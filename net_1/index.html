<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> The Impact of GPU Networking (Part 1) | Scale Ops </title> <meta name="author" content=" "> <meta name="description" content="This post examines the impact of GPU networking on transformer model training performance using Distributed Data Parallel (DDP), comparing high-speed intra-node NVLink with slower inter-node InfiniBand."> <meta name="keywords" content="HPC, AI, ML, gpus, scaling, llms, transformers, parallelism, profiling, performance"> <link rel="stylesheet" href="/scale-ops/assets/css/bootstrap.min.css?16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/scale-ops/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/scale-ops/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/scale-ops/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/scale-ops/assets/img/favicon.png?cd856673a519774152b6b16a4efad7c4"> <link rel="stylesheet" href="/scale-ops/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tomaslaz.github.io/scale-ops/net_1/"> <script src="/scale-ops/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/scale-ops/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/scale-ops/assets/js/distillpub/template.v2.js"></script> <script src="/scale-ops/assets/js/distillpub/transforms.v2.js"></script> <style type="text/css">.fake-img{background:#bbb;border:1px solid rgba(0,0,0,0.1);box-shadow:0 0 4px rgba(0,0,0,0.1);margin-bottom:12px}.fake-img p{font-family:monospace;color:white;text-align:left;margin:12px 0;text-align:center;font-size:16px}</style> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "The Impact of GPU Networking (Part 1)",
            "description": "This post examines the impact of GPU networking on transformer model training performance using Distributed Data Parallel (DDP), comparing high-speed intra-node NVLink with slower inter-node InfiniBand.",
            "published": "March 14, 2025",
            "authors": [
              
              {
                "author": "Tomas",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <script>
    function goToTop() {
      document.body.scrollTop = 0; // For Safari
      document.documentElement.scrollTop = 0; // For Chrome, Firefox, IE and Opera
    }

    // When the user scrolls down 20px from the top of the document, show the button
    window.onscroll = function () {
      scrollFunction();
    };

    function scrollFunction() {
      // Get the button:
      let mybutton = document.getElementById('top-button');

      if (document.body.scrollTop > 40 || document.documentElement.scrollTop > 40) {
        mybutton.style.display = 'block';
      } else {
        mybutton.style.display = 'none';
      }
    }
  </script> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/scale-ops/"> Scale Ops </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="left-button section-button"> <a href=".."> <svg viewbox="-78.5 0 512 512"> <path d="M257 64L291 98 128 262 291 426 257 460 61 262 257 64Z"></path> </svg> </a> </div> <div class="right-button section-button"> <a href="../net_2"> <svg viewbox="-78.5 0 512 512"> <path d="M98 460L64 426 227 262 64 98 98 64 294 262 98 460Z"></path> </svg> </a> </div> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/scale-ops/"> </a> </li> <li class="nav-item nav-hidden"><a class="nav-link" onclick="goToTop()" id="top-button" style="display: none;">Back to Top</a></li> <li class="nav-item nav-hidden"><p class="nav-link"></p></li> <li class="nav-item nav-hidden"><a class="nav-link" href="..">Previous Part</a></li> <li class="nav-item nav-hidden"><a class="nav-link" href="../net_2">Next Part</a></li> <li class="nav-item nav-hidden"><p class="nav-link"></p></li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Topics </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/scale-ops/index">Introduction</a> <a class="dropdown-item " href="/scale-ops/net_1">Networking Part 1</a> <a class="dropdown-item " href="/scale-ops/net_2">Networking Part 2</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>The Impact of GPU Networking (Part 1)</h1> <p>This post examines the impact of GPU networking on transformer model training performance using Distributed Data Parallel (DDP), comparing high-speed intra-node NVLink with slower inter-node InfiniBand.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#initial-hypotheses">Initial Hypotheses</a> </div> <div> <a href="#prior-knowledge">Prior Knowledge</a> </div> <div> <a href="#experimental-setup">Experimental Setup</a> </div> <div> <a href="#experiments">Experiments</a> </div> <div> <a href="#analysis">Analysis</a> </div> <div> <a href="#communication-benchmark-experiments">Communication Benchmark Experiments</a> </div> <div> <a href="#conclusions">Conclusions</a> </div> <div> <a href="#next-steps">Next Steps</a> </div> <div> <a href="#additional-information">Additional Information</a> </div> </nav> </d-contents> <p>The question of how much GPU interconnects influence training performance in large transformer-based models recently sparked a lively discussion with a colleague. Specifically, we debated whether, for simpler parallelism approaches—namely distributed data parallelism (DDP)—network bandwidth and latency still affect performance as strongly as they do for more communication-heavy strategies, such as model parallelism.</p> <p>In data parallelism, each GPU independently processes a slice of the overall batch, requiring gradients to be synchronized at each training step. Because this synchronization involves only the transfer of gradients—rather than splitting the entire model across devices, as in model parallelism—it is tempting to assume that the interconnect between GPU nodes might not be a major bottleneck.</p> <p>To gain empirical insights, I conducted a series of experiments using PyTorch Lightning and DDP. In this post, I document my process, present the experimental results, and reflect on what they reveal about GPU interconnects in multi-GPU training. While this is not a formal research paper, I hope it serves as a helpful exploration of how networking can affect large-scale transformer training.</p> <h2 id="initial-hypotheses">Initial Hypotheses</h2> <ul> <li> <p><strong>H1</strong>: For DDP, the interconnect between GPUs or GPU nodes is not a significant factor in training time for large transformer models.</p> </li> <li> <p><strong>H2</strong>: When training transformer models with DDP, scaling up the number of GPUs results in near-linear speedups.</p> </li> </ul> <p>My prior experience with both training transformer-based models and running large-scale HPC simulations made me skeptical of these hypotheses. However, I wanted to test them rigorously rather than rely on intuition or anecdotal evidence.</p> <h2 id="prior-knowledge">Prior Knowledge</h2> <p>In previous work published on <a href="https://zenodo.org/records/13349541" rel="external nofollow noopener" target="_blank">Zenodo</a>, I evaluated different HPC configurations for training GPT-2 and explored various parallelism strategies. Those findings hinted that:</p> <ul> <li>Some HPC services in the UK exhibit differences in setup that lead to noticeable variation in training performance.</li> <li>DDP can show near-linear scaling in certain scenarios, but network details matter once the model size grows large.</li> </ul> <p>I set out to expand on these observations here by running new experiments in a more controlled setting.</p> <h3 id="what-is-gpt-2">What is GPT-2?</h3> <p>GPT-2 is a transformer-based language model designed for text generation. Its architecture leverages self-attention mechanisms, allowing it to effectively model contextual relationships in sequences of text. In my experiments, I worked with two variants:</p> <ul> <li>GPT-2: ~85 million parameters</li> <li>GPT-2 Large: ~708 million parameters</li> </ul> <p>These models were trained in BF16 precision, with a batch size of 16, on the Shakespeare dataset. The training code relies on <a href="https://github.com/tomaslaz/lit-GPT" rel="external nofollow noopener" target="_blank">lightning-GPT</a>, which wraps the <a href="https://github.com/karpathy/minGPT" rel="external nofollow noopener" target="_blank">minGPT</a> implementation in PyTorch Lightning to simplify multi-GPU experiments.</p> <h3 id="distributed-data-parallelism-ddp">Distributed Data Parallelism (DDP)</h3> <p><a href="https://lightning.ai/docs/pytorch/1.9.5/" rel="external nofollow noopener" target="_blank">PyTorch Lightning</a> is a lightweight PyTorch wrapper for high-performance AI research, designed to abstract most boilerplate code and provide a high-level interface for training models. lightning-GPT enables training on multiple GPUs and nodes, supporting different parallelism strategies; for this work, I focus only on <a href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html" rel="external nofollow noopener" target="_blank">DDP</a>.</p> <p>When using DDP, gradient synchronization across GPUs happens every step when a batch is processed. The batch is split across the GPUs into smaller portions (mini-batches). Each GPU processes a different mini-batch of data in parallel during each training step. After computing gradients locally on their portion of the data, GPUs synchronize these gradients using an all-reduce operation to ensure consistency across the entire model.</p> <h2 id="experimental-setup">Experimental Setup</h2> <p>The experiments were conducted on <a href="https://www.baskerville.ac.uk/" rel="external nofollow noopener" target="_blank">Baskerville</a>, a GPU cluster at the University of Birmingham. Each node contains four NVIDIA A100 GPUs (40GB/80GB) connected via NVLink 3.0, and nodes are interconnected with InfiniBand HDR (see Appendix A for system specifications).</p> <h3 id="measurement-approach">Measurement Approach</h3> <p>I recorded the time taken to complete the second epoch of training. This approach helps:</p> <ul> <li>Avoid initialization overheads in the first epoch.</li> <li>Provide a realistic sense of how sustained training performance scales with different hardware configurations.</li> </ul> <p>The second epoch timing captures the pure training speed once the framework has loaded the data and established the initial model states.</p> <h2 id="experiments">Experiments</h2> <h3 id="gpt-2-experiments">GPT-2 Experiments</h3> <p>I first tested the smaller GPT-2 model (~85M parameters) with different node/GPU configurations:</p> <p><strong>Results</strong>:</p> <table> <thead> <tr> <th>Experiment</th> <th>Model</th> <th>Parallelism</th> <th>Nodes</th> <th>GPUs per Node</th> <th>Epoch 2 time (s)</th> <th>Peak memory (MiB)</th> </tr> </thead> <tbody> <tr> <td>e-15-1</td> <td>gpt2</td> <td>DDP</td> <td>1</td> <td>1</td> <td>157.60</td> <td>3,687.91</td> </tr> <tr> <td>e-15-2</td> <td>gpt2</td> <td>DDP</td> <td>1</td> <td>2</td> <td>62.96</td> <td>3,693.55</td> </tr> <tr> <td>e-15-3</td> <td>gpt2</td> <td>DDP</td> <td>2</td> <td>1</td> <td>62.55</td> <td>3,696.01</td> </tr> </tbody> </table> <p><strong>Observations</strong>:</p> <ul> <li>As expected, using more GPUs decreases training time.</li> <li>For the smaller GPT-2 model, there is no significant difference whether both GPUs are on the same node or on different nodes.</li> <li>These results initially seem to support H1 (reduced importance of interconnect for small models) and H2 (strong scaling with an additional GPU).</li> </ul> <h3 id="gpt-2-large-experiments">GPT-2 Large Experiments</h3> <p>Next, I repeated the procedure with GPT-2 Large (~708M parameters):</p> <p><strong>Results</strong>:</p> <table> <thead> <tr> <th>Experiment</th> <th>Model</th> <th>Parallelism</th> <th>Nodes</th> <th>GPUs per Node</th> <th>Epoch 2 time (s)</th> <th>Peak memory (MiB)</th> </tr> </thead> <tbody> <tr> <td>e-15-4-1</td> <td>gpt2-large</td> <td>DDP</td> <td>1</td> <td>1</td> <td>498.37</td> <td>24,258.05</td> </tr> <tr> <td>e-15-5-3</td> <td>gpt2-large</td> <td>DDP</td> <td>1</td> <td>2</td> <td>266.83</td> <td>24,258.38</td> </tr> <tr> <td>e-15-6-2</td> <td>gpt2-large</td> <td>DDP</td> <td>2</td> <td>1</td> <td>406.12</td> <td>24,297.53</td> </tr> </tbody> </table> <p><strong>Observations</strong>:</p> <ul> <li>Again, adding more GPUs reduces training time, but the effect is more complex than with the smaller model.</li> <li>When the GPUs are located on different nodes (Experiment e-15-6-2), the epoch time is substantially slower than when both GPUs are on the same node (e-15-5-3).</li> <li>These results suggest that interconnect performance starts to matter significantly for larger models, contradicting both H1 and H2.</li> </ul> <h2 id="analysis">Analysis</h2> <p>For GPT-2 Large, the number of steps per epoch differs based on the number of GPUs:</p> <ul> <li>Single GPU (e-15-4-1): 2,216 steps</li> <li>Two GPUs (e-15-5-3 and e-15-6-2): 1,108 steps</li> </ul> <p>The theoretical peak transfer speeds are:</p> <ul> <li>NVLink 3.0: 600 GB/s</li> <li>InfiniBand HDR: 200 Gbps (25 GB/s)</li> </ul> <p>Model Size Calculation:</p> <ul> <li>GPT-2 Large has 708 million parameters.</li> <li>Model size in BF16 precision: 708 _ 10^6 _ 16 bits / 8 bits per byte = 1.416 GB</li> </ul> <p>Total Data Transfer per Epoch:</p> <ul> <li>For 1,108 steps, and considering the all-reduce operation requires two transfers per step:</li> <li>Total data transferred: 2 _ 1.416 GB _ 1,108 = 3.14 TB</li> </ul> <p>Communication Time Estimates:</p> <ul> <li>NVLink 3.0: 3.14 TB / 600 GB/s = 5.23 s</li> <li>InfiniBand HDR: 3.14 TB / 25 GB/s = 125.6 s</li> </ul> <p>Comparing to Measured Times:</p> <ul> <li>Half of Single GPU Time: 498.37 s / 2 = 249.19 s. <ul> <li>This illustrates the ideal case where the training time halves with the addition of a second GPU assuming no communication overhead.</li> </ul> </li> <li>Estimated Time with NVLink 3.0: 249.19 s + 5.23 s = 254.42 s <ul> <li>Align reasonably well with the observed timing in e-15-5-3: 266.83 s</li> </ul> </li> <li>Estimated Time with InfiniBand HDR: 249.19 s + 125.6 s = 374.79 s <ul> <li>Align reasonably well with the observed timing in e-15-6-2: 406.12 s</li> </ul> </li> </ul> <p>Note: The discrepancies are likely due to factors like latency, network overhead, and resource contention.</p> <h2 id="communication-benchmark-experiments">Communication Benchmark Experiments</h2> <p>To isolate the communication overhead, I wrote a small benchmark <a href="../assets/scripts/bench_allreduce.py">script</a> measuring the throughput of a distributed all-reduce on 700M parameters in BF16 (~1.32 GB). The script relies on PyTorch’s collective communication (NCCL or Gloo) and reports the effective transfer speed:</p> <p><strong>Results</strong>:</p> <table> <thead> <tr> <th>Experiment</th> <th>Nodes</th> <th>GPUs per Node</th> <th>Backend</th> <th>Protocol</th> <th>Measured Transfer speed (GB/s)</th> <th>Time (s)</th> </tr> </thead> <tbody> <tr> <td>e-16-1</td> <td>1</td> <td>2</td> <td>NVLink 3.0</td> <td>NCCL</td> <td>159.29</td> <td>0.02</td> </tr> <tr> <td>e-16-1</td> <td>1</td> <td>2</td> <td>PCIe 4.0</td> <td>NCCL</td> <td>26.90</td> <td>0.10</td> </tr> <tr> <td>e-16-2</td> <td>2</td> <td>1</td> <td>InfiniBand (HDR)</td> <td>NCCL</td> <td>21.67</td> <td>0.12</td> </tr> <tr> <td>e-16-2</td> <td>2</td> <td>1</td> <td>Ethernet (25GbE)</td> <td>NCCL</td> <td>3.01</td> <td>0.88</td> </tr> <tr> <td>e-16-2</td> <td>2</td> <td>1</td> <td>InfiniBand (HDR)</td> <td>Gloo</td> <td>1.60</td> <td>1.70</td> </tr> <tr> <td>e-16-2</td> <td>2</td> <td>1</td> <td>Ethernet (25GbE)</td> <td>Gloo</td> <td>1.60</td> <td>1.65</td> </tr> </tbody> </table> <p><strong>Observations</strong>:</p> <ul> <li>NVLink (intra-node) throughput is orders of magnitude higher than inter-node InfiniBand.</li> <li>Times align with the differences observed in full training experiments: communication overhead grows substantially once multiple nodes are involved and model size is large.</li> </ul> <h3 id="recalculating-training-time-differences">Recalculating Training Time Differences:</h3> <p>For e-15-5-3 (NVLink 3.0), additional time due to communication:</p> <ul> <li>1,108 * 0.02 s = 22.16 s</li> <li>Total estimated time: 249.19 s + 22.16 s = 271.35 s</li> <li>Close to measured time: 266.83 s</li> </ul> <p>For e-15-6-2 (InfiniBand HDR), additional time due to communication:</p> <ul> <li>1,108 * 0.12 s = 132.96 s</li> <li>Total estimated time: 249.19 s + 132.96 s = 382.15 s</li> <li>Close to measured time: 406.12 s</li> </ul> <p>Again, discrepancies are due to other factors affecting training time.</p> <h2 id="conclusions">Conclusions</h2> <p>These experiments demonstrate that as transformer models grow larger, the significance of GPU interconnects becomes harder to ignore—even in Distributed Data Parallel setups. For smaller models like GPT-2 (~85M parameters), interconnect speed has minimal effect, in line with initial hypotheses H1 and H2. However, GPT-2 Large (~708M parameters) reveals a striking gap between intra-node NVLink performance and inter-node InfiniBand.</p> <p>In short:</p> <ul> <li>H1 and H2 are not supported by the data.</li> <li>Interconnect efficiency matters significantly for large-scale DDP workloads.</li> <li>Adding more GPUs does not guarantee near-linear speedups if inter-node bandwidth lags behind intra-node connectivity.</li> </ul> <h2 id="next-steps">Next Steps</h2> <p>In the <a href="../net_2">Part 2</a>, I will extend these experiments to 4 GPUs spread across 1, 2, and 4 nodes. This will shed further light on how network topologies (e.g., ring versus tree) influence performance when the number of GPUs per node varies.</p> <h1 id="additional-information">Additional Information</h1> <h2 id="appendix-a-baskerville-hpc-system-specifications">Appendix A: Baskerville HPC System Specifications</h2> <p>The experiments were conducted on the <a href="https://www.baskerville.ac.uk/" rel="external nofollow noopener" target="_blank">Baskerville</a> HPC system, which has the following specifications:</p> <h3 id="compute-nodes">Compute Nodes</h3> <p>There are 57 SD650-N V2 liquid-cooled compute trays with:</p> <ul> <li>2× Intel® Xeon® Platinum 8360Y CPUs, each with 36 cores at 2.4GHz (boost up to 3.5GHz)</li> <li>512GB RAM (16× 32GB DDR4)</li> <li>1TB NVMe M.2 device (used for the OS and available as /scratch-local)</li> <li>1× 25GbE NVIDIA® Mellanox® adapter (on-planar ConnectX-4 port)</li> <li>1× HDR (200Gbps) NVIDIA Mellanox Infiniband port (ConnectX-6 PCIe Gen4 adapter)</li> <li>NVIDIA HGX-100 GPU planar</li> <li>4× NVIDIA A100 GPUs</li> </ul> <p>The GPUs on 11 nodes have 80GB RAM, while those on the remaining 46 nodes have 40GB RAM. The GPUs are interconnected using NVIDIA NVLINK.</p> <h3 id="network">Network</h3> <p>Baskerville uses three networks:</p> <ul> <li>An isolated 1GbE management network (not user-accessible)</li> <li>A 25GbE high-speed Ethernet network built using NVIDIA Mellanox Spectrum®-2 switches running NVIDIA Cumulus® Linux</li> <li>An HDR fat-tree InfiniBand network built using NVIDIA Mellanox Quantum HDR switches (QM8790) and ConnectX-6 PCIe gen 4 adapters which provides a full 200Gb network connection</li> </ul> <h3 id="storage">Storage</h3> <p>The system is equipped with Lenovo DSS-G storage systems running IBM® Spectrum Scale™:</p> <ul> <li>1× DSS-G250 equipped with 418× 16TB HDD</li> <li>1× DSS-G204 equipped with 48× 7.68TB SSD</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/scale-ops/assets/bibliography/"></d-bibliography> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2025 . Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/scale-ops/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/scale-ops/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/scale-ops/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/scale-ops/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/scale-ops/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/scale-ops/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/scale-ops/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/scale-ops/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/scale-ops/assets/js/vanilla-back-to-top.min.js?eaf77346e117baa09987a278a117b9a7"></script> <script>
    addBackToTop();
  </script> </body> </html>